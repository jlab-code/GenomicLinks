{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61cef8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 09:37:35.640848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-21 09:37:35.694388: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-21 09:37:36.021116: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:/usr/local/cuda-11.7/lib64\n",
      "2024-04-21 09:37:36.021147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64:/usr/local/cuda-11.7/lib64\n",
      "2024-04-21 09:37:36.021150: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "## ATTENTION: BEVOR RUNNING PLEASE SELECT A NEW runNAME - check register!!!!!\n",
    "import os\n",
    "os.chdir(\"/mnt/storage1/deep_contact_luca/DP2500k/codes\")\n",
    "dir2save = \"/mnt/storage1/deep_contact_luca/DP2500k/results_logs/\"\n",
    "######### SELECT runNAME ####################\n",
    "runName = \"dp2500-01/24\"\n",
    "#############################################\n",
    "\n",
    "import util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import metrics\n",
    "from keras.models import Model\n",
    "from keras.layers import (\n",
    "    concatenate, Dense, LSTM, Input, Convolution1D,\n",
    "    MaxPooling1D, BatchNormalization, Dropout,\n",
    "    Bidirectional, Flatten, CuDNNLSTM\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping, CSVLogger\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import sklearn.preprocessing as skprep\n",
    "import csv\n",
    "import re\n",
    "import subprocess\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd150a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Configuration values\n",
    "data_dir = \"/mnt/storage1/deep_contact_luca/DP2500k/data\"\n",
    "data_samples_to_use = 202333\n",
    "HiChip_marks = \"k4me_2500,k27me_2500\"\n",
    "#percent_in_test_set = 10\n",
    "two_neurons_output = False\n",
    "HDF5_samples_num = 202333\n",
    "ATAC_based_negative_samples = False\n",
    "using_histones = False\n",
    "using_H3 = False\n",
    "using_ATAC = False\n",
    "using_fasta_seq = True\n",
    "using_meth_info = False\n",
    "\n",
    "num_fasta_seq_rows = 4 if using_fasta_seq else 0\n",
    "\n",
    "num_seq_signals_excluding_histones = using_H3 + using_ATAC + num_fasta_seq_rows + using_meth_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b068dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):    \n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
    "    return true_negatives / (possible_negatives + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1989a9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GenomicLinks\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 2500, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 2500, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 2437, 256)    65792       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 2437, 256)    65792       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 1217, 256)   0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPooling1D)  (None, 1217, 256)   0           ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 1186, 512)    4194816     ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 1186, 512)    4194816     ['max_pooling1d_6[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 592, 512)    0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPooling1D)  (None, 592, 512)    0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1184, 512)    0           ['max_pooling1d_5[0][0]',        \n",
      "                                                                  'max_pooling1d_7[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1184, 512)    0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 512)         1576960     ['dropout_2[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 512)          0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          262656      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 512)         2048        ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 512)          0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            513         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,363,393\n",
      "Trainable params: 10,362,369\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    # Hyperparameters\n",
    "    num_filters = [256, 512]\n",
    "    kernel_sizes = [64, 32, 16]\n",
    "    pool_sizes = [4, 4, 4]\n",
    "    stride_sizes = [2, 2, 2]\n",
    "    lstm_units = [256, 256]\n",
    "    dropout_rate = 0.5\n",
    "    dense_units = 512\n",
    "    dense_activation = 'tanh'\n",
    "    dense_dropout_rate = 0.3\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    # Input layers\n",
    "    input1 = Input(shape=(2500, 4))\n",
    "    input2 = Input(shape=(2500, 4))\n",
    "\n",
    "    # Convolutional layers and pooling for the first sequence\n",
    "    conv1a = Convolution1D(filters=num_filters[0], kernel_size=kernel_sizes[0], padding=\"valid\", activation='relu',\n",
    "                           kernel_regularizer=l2(1e-3))(input1)\n",
    "    pool1a = MaxPooling1D(pool_size=pool_sizes[0], strides=stride_sizes[0])(conv1a)\n",
    "    conv2a = Convolution1D(filters=num_filters[1], kernel_size=kernel_sizes[1], padding=\"valid\", activation='relu',\n",
    "                           kernel_regularizer=l2(1e-3))(pool1a)\n",
    "    pool2a = MaxPooling1D(pool_size=pool_sizes[1], strides=stride_sizes[1])(conv2a)\n",
    "\n",
    "    # Convolutional layers and pooling for the second sequence\n",
    "    conv1b = Convolution1D(filters=num_filters[0], kernel_size=kernel_sizes[0], padding=\"valid\", activation='relu',\n",
    "                           kernel_regularizer=l2(1e-3))(input2)\n",
    "    pool1b = MaxPooling1D(pool_size=pool_sizes[0], strides=stride_sizes[0])(conv1b)\n",
    "    conv2b = Convolution1D(filters=num_filters[1], kernel_size=kernel_sizes[1], padding=\"valid\", activation='relu',\n",
    "                           kernel_regularizer=l2(1e-3))(pool1b)\n",
    "    pool2b = MaxPooling1D(pool_size=pool_sizes[1], strides=stride_sizes[1])(conv2b)\n",
    "\n",
    "    # Merge the outputs\n",
    "    merged = concatenate([pool2a, pool2b], axis=1)\n",
    "    dropout = Dropout(dropout_rate)(merged)\n",
    "\n",
    "    # Bidirectional LSTM layer\n",
    "    lstm = Bidirectional(CuDNNLSTM(units=lstm_units[0]))(dropout)\n",
    "    flatten = Flatten()(lstm)\n",
    "\n",
    "    # Dense layers\n",
    "    dense = Dense(dense_units, activation=dense_activation)(flatten)\n",
    "    batch_norm = BatchNormalization()(dense)\n",
    "    dropout2 = Dropout(dense_dropout_rate)(batch_norm)\n",
    "\n",
    "    # Output layer\n",
    "    output = Dense(units=1, activation='sigmoid')(dropout2)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=[input1, input2], outputs=output, name='GenomicLinks')\n",
    "    \n",
    "    # Compile the model - add more metrics\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate),\n",
    "                  metrics=[metrics.SpecificityAtSensitivity(0.5), 'accuracy', specificity])\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', specificity])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb70226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start reading h5\n",
      "start_time_start_reading_H5\n",
      "--- 1.1920928955078125e-06 seconds ---\n",
      "reading H5 file done\n",
      "--- 12.603403806686401 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def start_dp():\n",
    "    h5_filename = \"/mnt/storage1/defne_dc/data/regions_labels_rand_neg_202344.h5\"\n",
    "    num_seq_signals = 4\n",
    "    train_r1, train_r2, train_labels, valid_r1, valid_r2, valid_labels, test_r1, test_r2, test_labels = util.data_to_train_test(h5_filename, data_samples_to_use)\n",
    "    return train_r1, train_r2, train_labels, valid_r1, valid_r2, valid_labels, test_r1, test_r2, test_labels\n",
    "\n",
    "# Now this function returns 9 variables instead of 3 or 6.\n",
    "train_r1, train_r2, train_labels, valid_r1, valid_r2, valid_labels, test_r1, test_r2, test_labels = start_dp()\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_specificity_at_sensitivity',\n",
    "                   patience=10,\n",
    "                   verbose=1,\n",
    "                   mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6cdb518",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_filename = dir2save + 'log_' + runName + '.csv'\n",
    "weights_filename = dir2save + 'weights-improvement-' + runName + '-{epoch:02d}.hdf5'\n",
    "\n",
    "csv_logger = CSVLogger(log_filename, append=True, separator=';')\n",
    "checkpoint = ModelCheckpoint(weights_filename, monitor='val_specificity_at_sensitivity', verbose=1,\n",
    "                             save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, csv_logger, es]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "294eda6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [np.asarray(train_r1, dtype=np.uint8), np.asarray(train_r2, dtype=np.uint8)]\n",
    "y_train = np.asarray(train_labels, dtype=np.uint8)\n",
    "\n",
    "# Update this part to use valid_r1, valid_r2, and valid_labels instead of test_r1, test_r2, and test_labels\n",
    "x_val = [np.asarray(valid_r1, dtype=np.uint8), np.asarray(valid_r2, dtype=np.uint8)]\n",
    "y_val = np.asarray(valid_labels, dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a195498e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 11:56:40.627885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8801\n",
      "2023-09-14 11:56:41.762291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619/1619 [==============================] - ETA: 0s - loss: 1.0267 - specificity_at_sensitivity: 0.4889 - accuracy: 0.5081 - specificity: 0.5137\n",
      "Epoch 1: val_specificity_at_sensitivity improved from -inf to 0.54878, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-01.hdf5\n",
      "1619/1619 [==============================] - 341s 209ms/step - loss: 1.0267 - specificity_at_sensitivity: 0.4889 - accuracy: 0.5081 - specificity: 0.5137 - val_loss: 0.8078 - val_specificity_at_sensitivity: 0.5488 - val_accuracy: 0.5305 - val_specificity: 0.6794\n",
      "Epoch 2/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.7391 - specificity_at_sensitivity: 0.6826 - accuracy: 0.5974 - specificity: 0.5990\n",
      "Epoch 2: val_specificity_at_sensitivity improved from 0.54878 to 0.80032, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-02.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.7391 - specificity_at_sensitivity: 0.6826 - accuracy: 0.5974 - specificity: 0.5990 - val_loss: 0.6865 - val_specificity_at_sensitivity: 0.8003 - val_accuracy: 0.6579 - val_specificity: 0.7461\n",
      "Epoch 3/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.5805 - specificity_at_sensitivity: 0.9209 - accuracy: 0.7582 - specificity: 0.7627\n",
      "Epoch 3: val_specificity_at_sensitivity improved from 0.80032 to 0.91121, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-03.hdf5\n",
      "1619/1619 [==============================] - 337s 208ms/step - loss: 0.5805 - specificity_at_sensitivity: 0.9209 - accuracy: 0.7582 - specificity: 0.7627 - val_loss: 0.6094 - val_specificity_at_sensitivity: 0.9112 - val_accuracy: 0.7477 - val_specificity: 0.7810\n",
      "Epoch 4/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.4400 - specificity_at_sensitivity: 0.9832 - accuracy: 0.8580 - specificity: 0.8616\n",
      "Epoch 4: val_specificity_at_sensitivity improved from 0.91121 to 0.95122, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-04.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.4400 - specificity_at_sensitivity: 0.9832 - accuracy: 0.8580 - specificity: 0.8616 - val_loss: 0.5844 - val_specificity_at_sensitivity: 0.9512 - val_accuracy: 0.7909 - val_specificity: 0.7572\n",
      "Epoch 5/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3562 - specificity_at_sensitivity: 0.9960 - accuracy: 0.9103 - specificity: 0.9129\n",
      "Epoch 5: val_specificity_at_sensitivity improved from 0.95122 to 0.95939, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-05.hdf5\n",
      "1619/1619 [==============================] - 336s 207ms/step - loss: 0.3562 - specificity_at_sensitivity: 0.9960 - accuracy: 0.9103 - specificity: 0.9129 - val_loss: 0.6257 - val_specificity_at_sensitivity: 0.9594 - val_accuracy: 0.8048 - val_specificity: 0.8741\n",
      "Epoch 6/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3174 - specificity_at_sensitivity: 0.9989 - accuracy: 0.9352 - specificity: 0.9374\n",
      "Epoch 6: val_specificity_at_sensitivity improved from 0.95939 to 0.96675, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-06.hdf5\n",
      "1619/1619 [==============================] - 336s 207ms/step - loss: 0.3174 - specificity_at_sensitivity: 0.9989 - accuracy: 0.9352 - specificity: 0.9374 - val_loss: 0.6465 - val_specificity_at_sensitivity: 0.9668 - val_accuracy: 0.8191 - val_specificity: 0.8217\n",
      "Epoch 7/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3045 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9470 - specificity: 0.9491\n",
      "Epoch 7: val_specificity_at_sensitivity improved from 0.96675 to 0.96904, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-07.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.3045 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9470 - specificity: 0.9491 - val_loss: 0.6581 - val_specificity_at_sensitivity: 0.9690 - val_accuracy: 0.8224 - val_specificity: 0.8014\n",
      "Epoch 8/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3021 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9531 - specificity: 0.9546\n",
      "Epoch 8: val_specificity_at_sensitivity improved from 0.96904 to 0.97163, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-08.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.3021 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9531 - specificity: 0.9546 - val_loss: 0.7284 - val_specificity_at_sensitivity: 0.9716 - val_accuracy: 0.8109 - val_specificity: 0.9099\n",
      "Epoch 9/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3006 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9571 - specificity: 0.9589\n",
      "Epoch 9: val_specificity_at_sensitivity improved from 0.97163 to 0.97462, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-09.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.3006 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9571 - specificity: 0.9589 - val_loss: 0.7197 - val_specificity_at_sensitivity: 0.9746 - val_accuracy: 0.8182 - val_specificity: 0.7413\n",
      "Epoch 10/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3008 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9594 - specificity: 0.9616\n",
      "Epoch 10: val_specificity_at_sensitivity did not improve from 0.97462\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.3008 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9594 - specificity: 0.9616 - val_loss: 0.7204 - val_specificity_at_sensitivity: 0.9734 - val_accuracy: 0.8237 - val_specificity: 0.7664\n",
      "Epoch 11/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3010 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9618 - specificity: 0.9638\n",
      "Epoch 11: val_specificity_at_sensitivity improved from 0.97462 to 0.97571, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-11.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.3010 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9618 - specificity: 0.9638 - val_loss: 0.6794 - val_specificity_at_sensitivity: 0.9757 - val_accuracy: 0.8282 - val_specificity: 0.7796\n",
      "Epoch 12/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3003 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9638 - specificity: 0.9652\n",
      "Epoch 12: val_specificity_at_sensitivity improved from 0.97571 to 0.97760, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-12.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.3003 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9638 - specificity: 0.9652 - val_loss: 0.7173 - val_specificity_at_sensitivity: 0.9776 - val_accuracy: 0.8299 - val_specificity: 0.7855\n",
      "Epoch 13/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2987 - specificity_at_sensitivity: 0.9993 - accuracy: 0.9665 - specificity: 0.9674\n",
      "Epoch 13: val_specificity_at_sensitivity did not improve from 0.97760\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2987 - specificity_at_sensitivity: 0.9993 - accuracy: 0.9665 - specificity: 0.9674 - val_loss: 0.6995 - val_specificity_at_sensitivity: 0.9715 - val_accuracy: 0.8357 - val_specificity: 0.8049\n",
      "Epoch 14/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.3008 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9666 - specificity: 0.9684\n",
      "Epoch 14: val_specificity_at_sensitivity did not improve from 0.97760\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.3008 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9666 - specificity: 0.9684 - val_loss: 0.7810 - val_specificity_at_sensitivity: 0.9621 - val_accuracy: 0.8227 - val_specificity: 0.7453\n",
      "Epoch 15/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2999 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9677 - specificity: 0.9694\n",
      "Epoch 15: val_specificity_at_sensitivity did not improve from 0.97760\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2999 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9677 - specificity: 0.9694 - val_loss: 0.7009 - val_specificity_at_sensitivity: 0.9733 - val_accuracy: 0.8407 - val_specificity: 0.8201\n",
      "Epoch 16/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2999 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9687 - specificity: 0.9698\n",
      "Epoch 16: val_specificity_at_sensitivity did not improve from 0.97760\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2999 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9687 - specificity: 0.9698 - val_loss: 0.7103 - val_specificity_at_sensitivity: 0.9772 - val_accuracy: 0.8385 - val_specificity: 0.8924\n",
      "Epoch 17/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2981 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9700 - specificity: 0.9718\n",
      "Epoch 17: val_specificity_at_sensitivity did not improve from 0.97760\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2981 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9700 - specificity: 0.9718 - val_loss: 0.7313 - val_specificity_at_sensitivity: 0.9731 - val_accuracy: 0.8383 - val_specificity: 0.7974\n",
      "Epoch 18/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2982 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9707 - specificity: 0.9719\n",
      "Epoch 18: val_specificity_at_sensitivity did not improve from 0.97760\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2982 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9707 - specificity: 0.9719 - val_loss: 0.7403 - val_specificity_at_sensitivity: 0.9691 - val_accuracy: 0.8372 - val_specificity: 0.7779\n",
      "Epoch 19/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2963 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9713 - specificity: 0.9729\n",
      "Epoch 19: val_specificity_at_sensitivity improved from 0.97760 to 0.97880, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-19.hdf5\n",
      "1619/1619 [==============================] - 336s 207ms/step - loss: 0.2963 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9713 - specificity: 0.9729 - val_loss: 0.7468 - val_specificity_at_sensitivity: 0.9788 - val_accuracy: 0.8378 - val_specificity: 0.9023\n",
      "Epoch 20/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2962 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9717 - specificity: 0.9734\n",
      "Epoch 20: val_specificity_at_sensitivity did not improve from 0.97880\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2962 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9717 - specificity: 0.9734 - val_loss: 0.7679 - val_specificity_at_sensitivity: 0.9644 - val_accuracy: 0.8353 - val_specificity: 0.7798\n",
      "Epoch 21/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2955 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9722 - specificity: 0.9729\n",
      "Epoch 21: val_specificity_at_sensitivity did not improve from 0.97880\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2955 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9722 - specificity: 0.9729 - val_loss: 0.7302 - val_specificity_at_sensitivity: 0.9781 - val_accuracy: 0.8457 - val_specificity: 0.8382\n",
      "Epoch 22/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2938 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9730 - specificity: 0.9740\n",
      "Epoch 22: val_specificity_at_sensitivity did not improve from 0.97880\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2938 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9730 - specificity: 0.9740 - val_loss: 0.7434 - val_specificity_at_sensitivity: 0.9784 - val_accuracy: 0.8418 - val_specificity: 0.9024\n",
      "Epoch 23/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2915 - specificity_at_sensitivity: 0.9996 - accuracy: 0.9735 - specificity: 0.9749\n",
      "Epoch 23: val_specificity_at_sensitivity did not improve from 0.97880\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2915 - specificity_at_sensitivity: 0.9996 - accuracy: 0.9735 - specificity: 0.9749 - val_loss: 0.7012 - val_specificity_at_sensitivity: 0.9767 - val_accuracy: 0.8489 - val_specificity: 0.8508\n",
      "Epoch 24/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2913 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9736 - specificity: 0.9755\n",
      "Epoch 24: val_specificity_at_sensitivity did not improve from 0.97880\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2913 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9736 - specificity: 0.9755 - val_loss: 0.7560 - val_specificity_at_sensitivity: 0.9653 - val_accuracy: 0.8397 - val_specificity: 0.7890\n",
      "Epoch 25/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2892 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9750 - specificity: 0.9760\n",
      "Epoch 25: val_specificity_at_sensitivity did not improve from 0.97880\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2892 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9750 - specificity: 0.9760 - val_loss: 0.7355 - val_specificity_at_sensitivity: 0.9762 - val_accuracy: 0.8463 - val_specificity: 0.8390\n",
      "Epoch 26/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2876 - specificity_at_sensitivity: 0.9996 - accuracy: 0.9748 - specificity: 0.9761\n",
      "Epoch 26: val_specificity_at_sensitivity improved from 0.97880 to 0.98109, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-26.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2876 - specificity_at_sensitivity: 0.9996 - accuracy: 0.9748 - specificity: 0.9761 - val_loss: 0.7366 - val_specificity_at_sensitivity: 0.9811 - val_accuracy: 0.8460 - val_specificity: 0.8960\n",
      "Epoch 27/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2873 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9753 - specificity: 0.9764\n",
      "Epoch 27: val_specificity_at_sensitivity did not improve from 0.98109\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2873 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9753 - specificity: 0.9764 - val_loss: 0.6779 - val_specificity_at_sensitivity: 0.9806 - val_accuracy: 0.8551 - val_specificity: 0.8704\n",
      "Epoch 28/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2873 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9750 - specificity: 0.9756\n",
      "Epoch 28: val_specificity_at_sensitivity did not improve from 0.98109\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2873 - specificity_at_sensitivity: 0.9995 - accuracy: 0.9750 - specificity: 0.9756 - val_loss: 0.7162 - val_specificity_at_sensitivity: 0.9796 - val_accuracy: 0.8520 - val_specificity: 0.8527\n",
      "Epoch 29/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2861 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9758 - specificity: 0.9769\n",
      "Epoch 29: val_specificity_at_sensitivity improved from 0.98109 to 0.98158, saving model to /mnt/storage1/deep_contact_luca/DP2500k/results_logs/weights-improvement-dp2500-1.1.09.23-29.hdf5\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2861 - specificity_at_sensitivity: 0.9994 - accuracy: 0.9758 - specificity: 0.9769 - val_loss: 0.7277 - val_specificity_at_sensitivity: 0.9816 - val_accuracy: 0.8501 - val_specificity: 0.8644\n",
      "Epoch 30/30\n",
      "1619/1619 [==============================] - ETA: 0s - loss: 0.2826 - specificity_at_sensitivity: 0.9996 - accuracy: 0.9765 - specificity: 0.9780\n",
      "Epoch 30: val_specificity_at_sensitivity did not improve from 0.98158\n",
      "1619/1619 [==============================] - 335s 207ms/step - loss: 0.2826 - specificity_at_sensitivity: 0.9996 - accuracy: 0.9765 - specificity: 0.9780 - val_loss: 0.7245 - val_specificity_at_sensitivity: 0.9765 - val_accuracy: 0.8524 - val_specificity: 0.8478\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 100\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b332bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 24s 38ms/step\n",
      "y_pred shape: (20233,)\n",
      "y_true shape: (20233,)\n",
      "Unique values in y_pred: [0. 1.]\n",
      "Unique values in y_true: [0 1]\n",
      "8602 1590 8562 1479\n"
     ]
    }
   ],
   "source": [
    "def predict(model, test_r1, test_r2, test_labels):\n",
    "    y_pred = model.predict([test_r1, test_r2]).flatten()  # Flatten to make it a 1D array\n",
    "    y_true = test_labels\n",
    "\n",
    "    # Debugging info\n",
    "    print(\"y_pred shape:\", y_pred.shape)\n",
    "    print(\"y_true shape:\", y_true.shape)\n",
    "    print(\"Unique values in y_pred:\", np.unique(np.round(y_pred)))\n",
    "    print(\"Unique values in y_true:\", np.unique(y_true))\n",
    "    \n",
    "    y_pred_rounded = np.round(y_pred)\n",
    "    \n",
    "    TP = np.sum((y_true == y_pred_rounded) & (y_true == 1))\n",
    "    FP = np.sum((y_pred_rounded == 1) & (y_true != y_pred_rounded))\n",
    "    TN = np.sum((y_true == y_pred_rounded) & (y_true == 0))\n",
    "    FN = np.sum((y_pred_rounded == 0) & (y_true != y_pred_rounded))\n",
    "    \n",
    "    return TP, FP, TN, FN, y_pred, y_true\n",
    "\n",
    "TP, FP, TN, FN, y_pred, y_true = predict(model, test_r1, test_r2, test_labels)\n",
    "print(TP, FP, TN, FN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65083cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.848\n",
      "Precision: 0.844\n",
      "Recall: 0.853\n",
      "F1 Score: 0.848\n",
      "Specificity: 0.843\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy\n",
    "accuracy = round((TP + TN) / (TP + TN + FP + FN), 3)\n",
    "\n",
    "# Calculate Precision\n",
    "precision = round(TP / (TP + FP), 3)\n",
    "\n",
    "# Calculate Recall/Sensitivity\n",
    "recall = round(TP / (TP + FN), 3)\n",
    "\n",
    "# Calculate F1 Score\n",
    "f1_score = round(2 * (precision * recall) / (precision + recall), 3)\n",
    "\n",
    "# Calculate Specificity\n",
    "specificity = round(TN / (TN + FP), 3)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b731fecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.925\n",
      "AUPRC: 0.926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "# y_pred should contain the predicted probabilities\n",
    "# y_true should be the true binary labels\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = round(roc_auc_score(y_true, y_pred), 3)\n",
    "\n",
    "# Calculate AUPRC\n",
    "auprc = round(average_precision_score(y_true, y_pred), 3)\n",
    "\n",
    "print(f\"ROC AUC: {roc_auc}\")\n",
    "print(f\"AUPRC: {auprc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44209145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
